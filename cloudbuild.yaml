# cloudbuild.yaml
# Builds image, pre-downloads HF weights during build (via build-arg secret),
# pushes to Artifact Registry, then uploads + deploys container to Vertex AI GPU endpoint.
# Trigger: text-to-speech should be configured to use this file.

substitutions:
  _REGION: "us-central1"
  _REPO_NAME: "text-to-speech"
  _IMAGE_NAME: "csm"
  _SERVICE_DISPLAY_NAME: "csm-vertex-service"

steps:
  # 0) Warm the Docker build cache by pulling the previously pushed image (if any)
  - name: 'gcr.io/cloud-builders/docker'
    entrypoint: 'bash'
    args:
      - -c
      - |
        set -e
        IMAGE_URI=${_REGION}-docker.pkg.dev/$PROJECT_ID/${_REPO_NAME}/${_IMAGE_NAME}
        docker pull $$IMAGE_URI:latest || true

  # 1) Build the image (inject HUGGINGFACE_TOKEN as build-arg for pre-download) with remote cache
  - name: 'gcr.io/cloud-builders/docker'
    entrypoint: 'bash'
    env:
      - DOCKER_BUILDKIT=1
      - BUILDKIT_INLINE_CACHE=1
    args:
      - -c
      - |
        set -e
        TAG=${SHORT_SHA:-$BUILD_ID}
        IMAGE_URI=${_REGION}-docker.pkg.dev/$PROJECT_ID/${_REPO_NAME}/${_IMAGE_NAME}
        docker build --pull \
          --build-arg HUGGINGFACE_TOKEN="$$HUGGINGFACE_TOKEN" \
          --cache-from $$IMAGE_URI:latest \
          -t $$IMAGE_URI:$$TAG \
          -t $$IMAGE_URI:latest \
          -f Dockerfile \
          .

  # 2) Push both the commit tag and latest to Artifact Registry
  - name: 'gcr.io/cloud-builders/docker'
    entrypoint: 'bash'
    args:
      - -c
      - |
        set -e
        TAG=${SHORT_SHA:-$BUILD_ID}
        IMAGE_URI=${_REGION}-docker.pkg.dev/$PROJECT_ID/${_REPO_NAME}/${_IMAGE_NAME}
        docker push $$IMAGE_URI:$$TAG

  - name: 'gcr.io/cloud-builders/docker'
    args:
      - push
      - ${_REGION}-docker.pkg.dev/$PROJECT_ID/${_REPO_NAME}/${_IMAGE_NAME}:latest

  # 3) Upload container image as a Vertex Model resource
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    entrypoint: 'bash'
    args:
      - -c
      - |
        set -euo pipefail

        IMAGE_URI=${_REGION}-docker.pkg.dev/$PROJECT_ID/${_REPO_NAME}/${_IMAGE_NAME}:latest
        echo "Uploading model resource using image: $$IMAGE_URI"
        MODEL_UPLOAD_OUT=$(gcloud ai models upload \
          --region=${_REGION} \
          --display-name="${_IMAGE_NAME}-model" \
          --container-image-uri="$$IMAGE_URI" \
          --format="get(name)" ) || (echo "model upload failed" && exit 1)
        echo "MODEL resource: $$MODEL_UPLOAD_OUT"
        MODEL_ID="$$MODEL_UPLOAD_OUT"

        # store model id to a file for later steps
        echo "$$MODEL_ID" > /workspace/last_model_id.txt

  # 4) Ensure a Vertex Endpoint exists (create if not)
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    entrypoint: 'bash'
    args:
      - -c
      - |
        set -euo pipefail
        REGION=${_REGION}
        EP_NAME="${_SERVICE_DISPLAY_NAME}"
        # try to find endpoint
        EXISTING=$(gcloud ai endpoints list --region=$$REGION --filter="displayName=$$EP_NAME" --format="value(name)" || true)
        if [ -z "$$EXISTING" ]; then
          echo "Creating endpoint $$EP_NAME in $$REGION"
          CREATED=$(gcloud ai endpoints create --region=$$REGION --display-name="$$EP_NAME" --format="get(name)")
          echo "$$CREATED" > /workspace/last_endpoint_id.txt
        else
          echo "Found existing endpoint: $$EXISTING"
          echo "$$EXISTING" > /workspace/last_endpoint_id.txt
        fi

  # 5) Deploy the model to the endpoint with GPU (a2-highgpu-1g / A100)
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    entrypoint: 'bash'
    args:
      - -c
      - |
        set -euo pipefail
        REGION=${_REGION}
        MODEL_ID=$(cat /workspace/last_model_id.txt)
        ENDPOINT_ID=$(cat /workspace/last_endpoint_id.txt)
        echo "Deploying model $$MODEL_ID -> endpoint $$ENDPOINT_ID"

        # If already deployed same model, skip; otherwise deploy new model
        gcloud ai endpoints deploy-model $$ENDPOINT_ID \
          --region=$$REGION \
          --model=$$MODEL_ID \
          --display-name="${_IMAGE_NAME}-deployed" \
          --machine-type="a2-highgpu-1g" \
          --accelerator-type="NVIDIA_A100" \
          --accelerator-count=1 \
          --min-replica-count=1 \
          --max-replica-count=1 \
          --traffic-split=0=100 \
          --quiet

images:
  - ${_REGION}-docker.pkg.dev/$PROJECT_ID/${_REPO_NAME}/${_IMAGE_NAME}:latest

timeout: "3600s"

options:
  logging: CLOUD_LOGGING_ONLY
